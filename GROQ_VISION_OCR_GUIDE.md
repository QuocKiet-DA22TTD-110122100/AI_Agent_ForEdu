# Groq Vision Support - OCR Image Reading

## T·ªïng quan

Groq models (Llama, Mixtral) kh√¥ng h·ªó tr·ª£ vision natively. ƒê·ªÉ Groq c√≥ th·ªÉ "hi·ªÉu" n·ªôi dung ·∫£nh, t√¥i ƒë√£ implement:

‚úÖ **EasyOCR** - ƒê·ªçc text t·ª´ ·∫£nh (ti·∫øng Anh + ti·∫øng Vi·ªát)
‚ö†Ô∏è **BLIP** (Optional) - M√¥ t·∫£ t·ªïng quan ·∫£nh (disabled m·∫∑c ƒë·ªãnh v√¨ model n·∫∑ng ~1GB)

## C√°ch ho·∫°t ƒë·ªông

### Khi user upload ·∫£nh v·ªõi Groq:

1. **Extract text** t·ª´ ·∫£nh b·∫±ng EasyOCR
2. **T·∫°o context** t·ª´ text ƒë√£ extract
3. **G·ª≠i context + c√¢u h·ªèi** cho Groq
4. Groq tr·∫£ l·ªùi d·ª±a tr√™n text context

### Khi user upload ·∫£nh v·ªõi Gemini:

- Gemini Vision API x·ª≠ l√Ω tr·ª±c ti·∫øp (native vision support)

## C√†i ƒë·∫∑t

```bash
cd backend/PythonService
pip install easyocr
```

## S·ª≠ d·ª•ng trong Frontend

**Kh√¥ng c·∫ßn thay ƒë·ªïi g√¨!** Frontend v·∫´n upload ·∫£nh nh∆∞ b√¨nh th∆∞·ªùng:

```typescript
// ChatPage.tsx - Upload ·∫£nh
const handleSend = async () => {
  await chatService.sendMessageWithActions(
    message,
    imageBase64,  // ‚Üê Base64 c·ªßa ·∫£nh
    imageMimeType // ‚Üê Mime type
  );
};
```

Backend t·ª± ƒë·ªông:
- **N·∫øu ch·ªçn Groq** ‚Üí D√πng OCR extract text
- **N·∫øu ch·ªçn Gemini** ‚Üí D√πng Vision API tr·ª±c ti·∫øp

## V√≠ d·ª•

### Test v·ªõi PowerShell:

```powershell
.\test_groq_vision.ps1
```

### Test trong UI:

1. M·ªü http://localhost:5173
2. Settings ‚Üí Ch·ªçn **Groq** (Llama 3.3 70B)
3. Click üìé ‚Üí Upload ·∫£nh c√≥ text
4. Groq s·∫Ω ƒë·ªçc text t·ª´ ·∫£nh v√† tr·∫£ l·ªùi!

## Gi·ªõi h·∫°n

### OCR Support:
- ‚úÖ Text r√µ r√†ng, c·ª° ch·ªØ v·ª´a ƒë·ªß
- ‚úÖ Ti·∫øng Anh, ti·∫øng Vi·ªát
- ‚ö†Ô∏è Ch·ªØ vi·∫øt tay (k√©m ch√≠nh x√°c)
- ‚ö†Ô∏è Text nh·ªè ho·∫∑c b·ªã m·ªù

### Kh√¥ng th·ªÉ:
- ‚ùå Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng (v·∫≠t, ng∆∞·ªùi, ƒë·ªông v·∫≠t)
- ‚ùå Ph√¢n t√≠ch m√†u s·∫Øc, b·ªë c·ª•c
- ‚ùå Hi·ªÉu ng·ªØ c·∫£nh visual ph·ª©c t·∫°p

‚Üí **D√πng Gemini** cho c√°c tr∆∞·ªùng h·ª£p tr√™n!

## Performance

- **OCR Loading**: ~2-3 gi√¢y l·∫ßn ƒë·∫ßu (load model)
- **OCR Processing**: ~1-2 gi√¢y/·∫£nh
- **Groq Response**: ~1-2 gi√¢y (r·∫•t nhanh!)

**T·ªïng**: ~3-7 gi√¢y (l·∫ßn ƒë·∫ßu), ~2-4 gi√¢y (l·∫ßn sau)

## T·ªëi ∆∞u

### K√≠ch ho·∫°t BLIP (n·∫øu c·∫ßn m√¥ t·∫£ ·∫£nh):

1. Edit `main.py`:
```python
# Uncomment d√≤ng n√†y
from transformers import BlipProcessor, BlipForConditionalGeneration
IMAGE_CAPTION_AVAILABLE = True
```

2. C√†i ƒë·∫∑t:
```bash
pip install transformers torch
```

**L∆∞u √Ω**: BLIP model ~1GB, t·ªën ~3-5 gi√¢y load l·∫ßn ƒë·∫ßu!

## Code Reference

### Backend: `main.py`

```python
def extract_image_content(image_base64, image_mime_type):
    # OCR extract text
    ocr_reader = get_ocr_reader()
    ocr_results = ocr_reader.readtext(image_data)
    text_lines = [text for (bbox, text, prob) in ocr_results]
    
    return {
        "text_content": "\n".join(text_lines),
        "description": f"Image: {format}, {width}x{height}",
        "success": True
    }
```

### Groq Integration:

```python
if request.ai_provider == "groq" and has_image:
    image_content = extract_image_content(image_base64, mime_type)
    
    # Build context
    image_context = f"""
    üì∏ N·ªòI DUNG T·ª™ ·∫¢NH:
    Text trong ·∫£nh: {image_content['text_content']}
    """
    
    # Send to Groq with context
    groq_response = groq_client.generate_text(
        prompt=f"{image_context}\n\n{user_question}"
    )
```

## So s√°nh Groq vs Gemini

| Feature | Groq + OCR | Gemini Vision |
|---------|------------|---------------|
| **ƒê·ªçc text** | ‚úÖ R·∫•t t·ªët | ‚úÖ Excellent |
| **Nh·∫≠n di·ªán v·∫≠t th·ªÉ** | ‚ùå Kh√¥ng | ‚úÖ Excellent |
| **Hi·ªÉu ng·ªØ c·∫£nh** | ‚ö†Ô∏è Gi·ªõi h·∫°n | ‚úÖ Excellent |
| **T·ªëc ƒë·ªô** | ‚ö° R·∫•t nhanh | ‚ö° Nhanh |
| **Cost** | üí∞ Mi·ªÖn ph√≠ | üí∞ C√≥ quota |

## Khi n√†o d√πng g√¨?

### D√πng Groq + OCR:
- ‚úÖ ·∫¢nh c√≥ nhi·ªÅu text (code, documents, slides)
- ‚úÖ C·∫ßn t·ªëc ƒë·ªô cao
- ‚úÖ ƒê√£ h·∫øt quota Gemini

### D√πng Gemini Vision:
- ‚úÖ ·∫¢nh kh√¥ng c√≥ text
- ‚úÖ C·∫ßn hi·ªÉu ng·ªØ c·∫£nh visual
- ‚úÖ Nh·∫≠n di·ªán v·∫≠t th·ªÉ, ng∆∞·ªùi, c·∫£nh

## Troubleshooting

### "OCR kh√¥ng kh·∫£ d·ª•ng":
```bash
pip install easyocr
```

### "Kh√¥ng t√¨m th·∫•y text trong ·∫£nh":
- Ki·ªÉm tra ·∫£nh c√≥ text r√µ r√†ng kh√¥ng
- Text c√≥ ƒë·ªß l·ªõn kh√¥ng (>12pt)
- ·∫¢nh c√≥ b·ªã m·ªù/nghi√™ng kh√¥ng

### OCR ch·∫≠m:
- L·∫ßn ƒë·∫ßu load model (b√¨nh th∆∞·ªùng)
- ·∫¢nh qu√° l·ªõn ‚Üí resize tr∆∞·ªõc khi g·ª≠i

## API Endpoint

```http
POST /api/chat
Content-Type: application/json

{
  "message": "Explain this code",
  "ai_provider": "groq",
  "model": "llama-3.3-70b-versatile",
  "image_base64": "base64_string_here",
  "image_mime_type": "image/jpeg"
}
```

**Response**:
```json
{
  "response": "Groq's answer based on extracted text...",
  "model": "llama-3.3-70b-versatile (Groq)",
  "rag_enabled": true
}
```

## Future Enhancements

- [ ] Support PDF text extraction
- [ ] Support handwriting recognition
- [ ] Cache OCR results
- [ ] Parallel OCR + Groq processing
- [ ] Custom OCR confidence threshold

---

**Status**: ‚úÖ Production Ready
**Last Updated**: December 24, 2025
